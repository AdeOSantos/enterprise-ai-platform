# ğŸš€ Enterprise AI Platform
**End-to-End MLOps + GenAI (Production-Grade Reference Architecture)**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Java](https://img.shields.io/badge/Java-17-orange.svg)](https://openjdk.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Go](https://img.shields.io/badge/Go-1.21+-00ADD8.svg)](https://golang.org/)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-1.28+-326CE5.svg)](https://kubernetes.io/)

---

## ğŸ“‹ Executive Summary

This repository demonstrates a **full-scale Enterprise AI Platform**, designed to reflect how modern companies build, deploy, operate, and evolve Machine Learning and Generative AI systems **in production**.

It goes far beyond notebooks and isolated models.  
The focus is on **architecture, reliability, observability, automation, and scale**.

This project is intended to clearly signal **real-world MLOps and AI platform experience** to senior engineers, architects, and recruiters within seconds.

---

## ğŸ‘¨â€ğŸ’» Author

<div align="center">

### **Adalberto Santos**

*Staff-Level Software Engineer | Event-Driven Architecture Specialist*

[![GitHub](https://img.shields.io/badge/GitHub-adeosantos-black?style=flat&logo=github)](https://github.com/adeosantos)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://linkedin.com/in/adalbertosantos)

</div>

---

## âœ¨ What This Project Shows (at a Glance)

- End-to-end **MLOps lifecycle**: training â†’ validation â†’ versioning â†’ deployment
- **Production model serving** via REST and gRPC
- **GenAI integration** with LLMs, agents, and prompt versioning
- **Observability**: latency, cost, errors, and model/data drift
- **CI/CD** for both application code and ML models
- **Infrastructure as Code** using Terraform
- **Cloud-native architecture** using Docker and Kubernetes
- Clear separation of concerns between data, ML, serving, infra, and ops

---

## ğŸ—ï¸ High-Level Architecture

```mermaid
flowchart LR
    A["Data Sources\n(Databases, Files, APIs, Events)"]
    B["Feature Engineering\nPipelines"]
    C["Training & Validation\n(Python)"]
    D["Experiment Tracking\n& Model Registry\n(MLflow / Kubeflow)"]
    E["Versioned Model Artifacts"]
    F["Model Serving APIs\n(Java / Golang)"]
    G["Kubernetes Cluster"]
    H["Consumers\n(Apps, Services)"]
    I["Observability\n(Latency, Cost, Drift)"]
    J["CI/CD Pipelines"]
    K["Infrastructure as Code\n(Terraform)"]

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H

    F --> I
    G --> I

    J --> C
    J --> F
    J --> G

    K --> G
```

---

## ğŸ¯ Core Design Principles

- **Production-first**: everything assumes real traffic, failures, and evolution
- **Reproducibility**: models, data, infra, and deployments are versioned
- **Automation by default**: no manual steps to train or deploy
- **Language-agnostic serving**: ML in Python, APIs in Java/Golang
- **Cloud portability**: AWS/GCPâ€“like architecture, runnable locally
- **Clear ownership boundaries**: ML, platform, and infra concerns are separated

---

## ğŸ› ï¸ Tech Stack

### Languages
- **Python** â€” training pipelines, feature engineering, evaluation
- **Java** â€” high-performance model serving (enterprise APIs)
- **Golang** â€” lightweight, low-latency serving alternatives

### MLOps
- **MLflow** or **Kubeflow Pipelines**
- Experiment tracking
- Model registry with lifecycle stages (dev / staging / prod)

### Infrastructure
- **Docker** â€” containerization
- **Kubernetes** â€” orchestration, scaling, rollouts
- **Terraform** â€” declarative infrastructure

### CI/CD
- Automated training and validation
- Model promotion gates
- Blue/green and canary deployments
- Rollbacks on regression

### Observability
- API latency and throughput
- Inference cost estimation
- Error rates
- Data and model drift detection

### GenAI
- LLM adapters
- Prompt versioning
- Agent-based multi-step workflows
- Cost and latency guardrails

---

## ğŸ“‚ Repository Structure

```
enterprise-ai-platform/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â”œâ”€â”€ build.gradle.kts              # Gradle build configuration
â”œâ”€â”€ settings.gradle.kts           # Gradle settings
â”‚
â”œâ”€â”€ data/                         # Data management
â”‚   â”œâ”€â”€ raw/                      # Raw data ingestion
â”‚   â”‚   â”œâ”€â”€ external/             # External data sources
â”‚   â”‚   â””â”€â”€ internal/             # Internal data sources
â”‚   â”œâ”€â”€ processed/                # Cleaned and transformed data
â”‚   â”‚   â”œâ”€â”€ cleaned/              # Cleaned datasets
â”‚   â”‚   â””â”€â”€ normalized/           # Normalized datasets
â”‚   â”œâ”€â”€ features/                 # Feature store outputs
â”‚   â”‚   â”œâ”€â”€ offline/              # Offline features for training
â”‚   â”‚   â””â”€â”€ online/               # Online features for serving
â”‚   â””â”€â”€ samples/                  # Sample datasets for testing
â”‚       â””â”€â”€ sample_dataset.csv
â”‚
â”œâ”€â”€ training/                     # ML training lifecycle
â”‚   â”œâ”€â”€ pipelines/                # Training orchestration
â”‚   â”‚   â”œâ”€â”€ train.py              # Main training pipeline
â”‚   â”‚   â”œâ”€â”€ validate.py           # Model validation
â”‚   â”‚   â”œâ”€â”€ promote.py            # Model promotion
â”‚   â”‚   â””â”€â”€ retrain_trigger.py   # Automated retraining logic
â”‚   â”œâ”€â”€ feature_engineering/      # Feature transformations
â”‚   â”‚   â”œâ”€â”€ transformations.py    # Feature transformations
â”‚   â”‚   â””â”€â”€ validators.py         # Feature validation
â”‚   â”œâ”€â”€ evaluation/               # Model evaluation metrics
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Evaluation metrics
â”‚   â”‚   â””â”€â”€ thresholds.yaml       # Quality thresholds
â”‚   â”œâ”€â”€ experiments/              # Experiment tracking (MLflow)
â”‚   â”‚   â””â”€â”€ experiment_runner.py
â”‚   â”œâ”€â”€ config/                   # Training configuration
â”‚   â”‚   â””â”€â”€ training.yaml
â”‚   â””â”€â”€ tests/                    # Training tests
â”‚       â””â”€â”€ test_training_pipeline.py
â”‚
â”œâ”€â”€ models/                       # Model management
â”‚   â”œâ”€â”€ registry/                 # Model version registry
â”‚   â”‚   â””â”€â”€ mlflow_registry.py
â”‚   â”œâ”€â”€ artifacts/                # Serialized model files
â”‚   â”‚   â”œâ”€â”€ model.pkl
â”‚   â”‚   â””â”€â”€ model.onnx
â”‚   â”œâ”€â”€ schemas/                  # Input/output schemas
â”‚   â”‚   â””â”€â”€ input_output_schema.json
â”‚   â””â”€â”€ metadata/                 # Model documentation
â”‚       â””â”€â”€ model_card.md
â”‚
â”œâ”€â”€ serving/                      # Production inference APIs
â”‚   â”œâ”€â”€ api-java/                 # Java-based serving (Spring Boot)
â”‚   â”‚   â”œâ”€â”€ src/main/java/        # Java source code
â”‚   â”‚   â”‚   â””â”€â”€ com/company/ai/
â”‚   â”‚   â”‚       â”œâ”€â”€ Application.java
â”‚   â”‚   â”‚       â”œâ”€â”€ controller/
â”‚   â”‚   â”‚       â”œâ”€â”€ service/
â”‚   â”‚   â”‚       â”œâ”€â”€ model/
â”‚   â”‚   â”‚       â””â”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ src/main/resources/   # Application resources
â”‚   â”‚   â”‚   â””â”€â”€ application.yml
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ pom.xml               # Maven configuration
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ api-golang/               # Go-based serving (high performance)
â”‚   â”‚   â”œâ”€â”€ cmd/server/           # Application entry point
â”‚   â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”‚   â”œâ”€â”€ internal/             # Internal packages
â”‚   â”‚   â”‚   â”œâ”€â”€ handler/
â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â””â”€â”€ registry/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ go.mod                # Go module definition
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ protos/                   # gRPC service definitions
â”‚       â””â”€â”€ inference.proto
â”‚
â”œâ”€â”€ genai/                        # Generative AI components
â”‚   â”œâ”€â”€ llm-adapters/             # Provider abstractions
â”‚   â”‚   â”œâ”€â”€ openai_adapter.py
â”‚   â”‚   â””â”€â”€ local_llm_adapter.py
â”‚   â”œâ”€â”€ prompt-engineering/       # Versioned prompts
â”‚   â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”‚   â””â”€â”€ base_prompt.txt
â”‚   â”‚   â”œâ”€â”€ versions/
â”‚   â”‚   â”‚   â””â”€â”€ v1.yaml
â”‚   â”‚   â””â”€â”€ evaluator.py
â”‚   â”œâ”€â”€ agents/                   # Multi-step AI agents
â”‚   â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”‚   â””â”€â”€ tools.py
â”‚   â”œâ”€â”€ evaluations/              # GenAI quality metrics
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ test_cases.json
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ genai.yaml
â”‚
â”œâ”€â”€ observability/                # Production monitoring
â”‚   â”œâ”€â”€ metrics/                  # Custom metrics (Prometheus)
â”‚   â”‚   â”œâ”€â”€ prometheus_rules.yaml
â”‚   â”‚   â””â”€â”€ exporter.py
â”‚   â”œâ”€â”€ tracing/                  # Distributed tracing (Jaeger/Tempo)
â”‚   â”‚   â””â”€â”€ otel_config.yaml
â”‚   â”œâ”€â”€ logging/                  # Structured logging
â”‚   â”‚   â””â”€â”€ log_config.yaml
â”‚   â”œâ”€â”€ drift-detection/          # Data and model drift
â”‚   â”‚   â”œâ”€â”€ data_drift.py
â”‚   â”‚   â””â”€â”€ model_drift.py
â”‚   â””â”€â”€ cost-monitoring/          # Inference cost tracking
â”‚       â””â”€â”€ cost_estimator.py
â”‚
â”œâ”€â”€ infra/                        # Infrastructure as Code
â”‚   â”œâ”€â”€ terraform/                # Cloud infrastructure
â”‚   â”‚   â”œâ”€â”€ modules/              # Reusable modules
â”‚   â”‚   â”‚   â”œâ”€â”€ kubernetes/
â”‚   â”‚   â”‚   â”œâ”€â”€ registry/
â”‚   â”‚   â”‚   â””â”€â”€ networking/
â”‚   â”‚   â”œâ”€â”€ envs/                 # Environment configs
â”‚   â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ kubernetes/               # K8s manifests
â”‚   â”‚   â”œâ”€â”€ base/                 # Base configurations
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â”‚   â””â”€â”€ overlays/             # Environment overlays (Kustomize)
â”‚   â”‚       â”œâ”€â”€ dev/
â”‚   â”‚       â”œâ”€â”€ staging/
â”‚   â”‚       â””â”€â”€ prod/
â”‚   â””â”€â”€ helm/                     # Helm charts
â”‚       â””â”€â”€ ai-platform-chart/
â”‚
â”œâ”€â”€ ci-cd/                        # CI/CD pipelines
â”‚   â”œâ”€â”€ model-pipeline/           # ML pipeline automation
â”‚   â”‚   â”œâ”€â”€ train.yml
â”‚   â”‚   â”œâ”€â”€ validate.yml
â”‚   â”‚   â””â”€â”€ deploy.yml
â”‚   â””â”€â”€ application-pipeline/     # Application deployment
â”‚       â”œâ”€â”€ build.yml
â”‚       â”œâ”€â”€ test.yml
â”‚       â””â”€â”€ release.yml
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ bootstrap.sh              # Environment setup
â”‚   â”œâ”€â”€ local_cluster.sh          # Local K8s cluster (kind/minikube)
â”‚   â””â”€â”€ cleanup.sh                # Resource cleanup
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ architecture.md           # System architecture
â”‚   â”œâ”€â”€ mlops_flow.md             # MLOps workflow
â”‚   â”œâ”€â”€ genai_design.md           # GenAI patterns
â”‚   â””â”€â”€ adr/                      # ADRs (Architecture Decision Records)
â”‚       â””â”€â”€ 0001-platform-decisions.md
â”‚
â””â”€â”€ examples/                     # Usage examples
    â”œâ”€â”€ notebooks/                # Jupyter notebooks
    â”‚   â””â”€â”€ exploration.ipynb
    â””â”€â”€ api-usage/                # API client examples
        â””â”€â”€ curl_examples.sh
```

Each folder maps directly to a **real enterprise responsibility**.

---

## ğŸ”„ Model Lifecycle (End-to-End)

1. **Data ingestion**
2. **Feature engineering**
3. **Model training**
4. **Validation & quality gates**
5. **Experiment tracking**
6. **Model registration**
7. **Automated promotion**
8. **Deployment to Kubernetes**
9. **Live inference via API**
10. **Monitoring & drift detection**
11. **Automated retraining triggers**

This reflects how AI systems are actually operated over time.

---

## ğŸš€ Model Serving Strategy

- Models are **not embedded** directly in applications
- APIs load models dynamically from a registry
- Supports:
    - REST for general consumers
    - gRPC for high-performance internal calls
- Independent scaling of:
    - Training workloads
    - Serving workloads

---

## ğŸ¤– GenAI Capabilities

This platform treats GenAI as a **first-class production system**, not a demo.

Included concepts:
- Prompt templates with versioning
- LLM provider abstraction
- Multi-step agent workflows
- Latency and token cost tracking
- Safe rollout of prompt changes

This mirrors how enterprises integrate LLMs responsibly.

---

## âš™ï¸ CI/CD Flow

**Model pipeline**
- Triggered by data or code changes
- Trains and validates models
- Automatically registers new versions
- Promotes only if metrics pass thresholds

**Application pipeline**
- Builds serving APIs
- Runs tests
- Produces container images
- Deploys via Kubernetes manifests or Helm

---

## ğŸ’» Getting Started

### Prerequisites

- **Docker** 24.0+
- **Kubernetes** (minikube, kind, or Docker Desktop)
- **Java** 17+
- **Python** 3.10+
- **Go** 1.21+
- **Terraform** 1.5+
- **Gradle** 8.0+

### Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/enterprise-ai-platform.git
   cd enterprise-ai-platform
   ```

2. **Bootstrap the environment**
   ```bash
   ./scripts/bootstrap.sh
   ```

3. **Start local Kubernetes cluster**
   ```bash
   ./scripts/local_cluster.sh
   ```

4. **Build the Java project**
   ```bash
   ./gradlew build
   ```

5. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

6. **Run training pipeline**
   ```bash
   python training/pipelines/train.py
   ```

7. **Deploy serving APIs**
   ```bash
   # Java API
   cd serving/api-java
   mvn clean package
   docker build -t ai-platform/java-api:latest .
   kubectl apply -f ../../infra/kubernetes/base/deployment.yaml
   kubectl apply -f ../../infra/kubernetes/base/service.yaml

   # Go API
   cd ../api-golang
   go build -o server cmd/server/main.go
   docker build -t ai-platform/go-api:latest .
   ```

8. **Test the APIs**
   ```bash
   # Wait for pods to be ready
   kubectl wait --for=condition=ready pod -l app=ai-inference --timeout=60s
   
   # Forward port to access API
   kubectl port-forward svc/ai-inference-api 8080:80
   
   # Run test requests
   ./examples/api-usage/curl_examples.sh
   ```

### Local Development

The platform is designed to run **locally** with:
- Local Kubernetes cluster (kind/minikube)
- Simulated cloud services
- Reproducible environments via Docker Compose
- Port-forwarded APIs for testing

This allows safe experimentation without cloud cost.

---

## ğŸ“ Key Learning Outcomes

This project demonstrates proficiency in:

- **MLOps Engineering**: End-to-end ML lifecycle management
- **Polyglot Development**: Python, Java, and Go in production
- **Cloud-Native Architecture**: Kubernetes, Docker, microservices
- **Infrastructure as Code**: Terraform, Helm, Kustomize
- **CI/CD Automation**: GitHub Actions, automated deployments
- **Production Observability**: Metrics, logging, tracing, alerting
- **GenAI Integration**: LLM APIs, agents, prompt management
- **API Design**: REST and gRPC services
- **System Design**: Scalability, reliability, maintainability

---

## ğŸ’¡ Why This Project Is High Impact

- Shows **systems thinking**, not just ML skills
- Demonstrates **real MLOps maturity**
- Combines backend, infra, and AI
- Matches how FAANG and large enterprises operate AI platforms
- Recruiters can assess seniority in under 30 seconds

This is the difference between *â€œknows MLâ€* and *â€œbuilds AI platformsâ€*.

---

## ğŸ¯ Intended Audience

- Senior / Staff Software Engineers
- AI Engineers beyond notebooks
- Backend / Platform engineers moving into AI
- Tech Leads and Architects
- Recruiters hiring for production AI roles

---

## ğŸ—ºï¸ Roadmap

- [ ] Add MLflow integration for experiment tracking
- [ ] Implement Kubeflow Pipelines for orchestration
- [ ] Add data drift detection with Evidently
- [ ] Integrate Prometheus and Grafana dashboards
- [ ] Add A/B testing framework for models
- [ ] Implement feature store (Feast)
- [ ] Add real-time streaming inference (Kafka + Flink)
- [ ] Deploy to AWS/GCP with Terraform
- [ ] Add model explainability (SHAP, LIME)
- [ ] Implement automated model retraining

---

## ğŸ¤ Contributing

Contributions are welcome! This is a learning and portfolio project.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“š Additional Resources

- [MLOps Principles](https://ml-ops.org/)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Terraform Best Practices](https://www.terraform-best-practices.com/)
- [GenAI Design Patterns](docs/genai_design.md)
- [Architecture Decision Records](docs/adr/)

---

## ğŸ“§ Contact

**Adalberto Santos**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: [Your Profile](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## âš ï¸ Disclaimer

This project is a **reference implementation** for learning and portfolio purposes.
It simulates enterprise systems without exposing proprietary data or infrastructure.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## â­ Show Your Support

If you find this project helpful, please give it a star! â­

---

**Built with â¤ï¸ to demonstrate production-grade AI platform engineering**